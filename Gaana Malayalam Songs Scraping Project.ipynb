{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b62f83c",
   "metadata": {},
   "source": [
    "# scraping malayalam song titles and track on Gaana\n",
    "\n",
    "TODO(intro):\n",
    " - Introduction about web scraping\n",
    " - Introduction about Gaana and problem statement\n",
    " - Mention the tools you are using(Python,request,Beautiful Soup,Pandas)\n",
    " \n",
    " \n",
    " Here are the steps we follow:\n",
    " - We are going to scrape https://gaana.com/album/malayalam\n",
    " - We will get a list of topics.For each topic, we'll get topic title,topic page Url\n",
    " - For each topic,we'll get 40 topic from the topic page\n",
    " - For each title page, we will get track name,artist name,duration,track url\n",
    " - For each topic we will create a csv file in the following format:\n",
    " \n",
    " track_name,artists_name,track_duration,track_url\n",
    " Teaser Theme,Ravi Basrur,02:16,https://gaana.com/song/teaser-theme-from-kgf-chapter-2-1\n",
    "  \n",
    "  \n",
    "  # scrape the list of song titles from Gaana\n",
    "  \n",
    "  explaning how we will do it.\n",
    "  \n",
    "  - use requests to download the page\n",
    "  - user BS4 to parse and extract information\n",
    "  - convert to a Pandas dataframe\n",
    "  \n",
    "  \n",
    "  \n",
    "  # write a single function to:\n",
    "\n",
    "1 get list of titles from the titles page\n",
    "2 get list of all tracks from individual titles\n",
    "3 for each titles create csv of the track for the title\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671c461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "140ac085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3e9cfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_titles_info():\n",
    "    #page we are gonna scrap titles\n",
    "        topic_url = 'https://gaana.com/album/malayalam'\n",
    "    #requesting the page    \n",
    "        response = requests.get(topic_url)\n",
    "        if response.status_code != 200:\n",
    "                raise Exception('Failed to load page {}'.format(movie_name_url))\n",
    "        page_contents = response.text\n",
    "    #parser the page content using beautifulsoup\n",
    "        doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "    #finding the tags in doc with required elements\n",
    "        movie_name_tags = doc.find_all('a',{'class':'al t_over'})\n",
    "    #extrating the elements from the doc\n",
    "        movie_name = []\n",
    "\n",
    "        for tags in movie_name_tags:\n",
    "            \n",
    "            movie_name.append(tags.text)\n",
    "\n",
    "        movie_name_url = []\n",
    "        base_url ='https://gaana.com'\n",
    "\n",
    "        for tags in movie_name_tags:\n",
    "            movie_name_url.append(base_url + tags['href'])\n",
    "   #creating a dict to contain the elements\n",
    "        topics_dict = {\n",
    "                   'title': movie_name,\n",
    "                  'url': movie_name_url\n",
    "                  } \n",
    "   #Making a pandas dataframe using the dict\n",
    "        return pd.DataFrame(topics_dict)\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "0b574f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to list the scrap the items we need\n",
    "def get_track1_info(track_name_tags,artists_name_tags,track_duration_tags,track_url_tags):\n",
    "        track_name = track_name_tags.text\n",
    "        artists_name = artists_name_tags.text\n",
    "        track_duration = track_duration_tags.text\n",
    "        track_url = base_url+track_url_tags['href']\n",
    "        return track_name, artists_name, track_duration, track_url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "76636a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_url(movie_name_url):\n",
    "    #requesting the title page\n",
    "        response = requests.get(movie_name_url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception('Failed to load page {}'.format(movie_name_url))\n",
    "    #parser it with BeatifulSoup\n",
    "        topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    #tags which contain required elements\n",
    "        track_name_tags = topic_doc.find_all('a',{'class':'_tra t_over _plyCr'})\n",
    "        artists_name_tags = topic_doc.find_all('div',{'class':'_art t_over'})\n",
    "        track_duration_tags = topic_doc.find_all('li',{'class':'_dur sm-hide'})\n",
    "        track_url_tags = topic_doc.find_all('a',{'class':'_tra t_over _plyCr'})\n",
    "        \n",
    "     \n",
    "      #creating a dict for the tracks in the titles  \n",
    "        topic_title_dict = {\n",
    "        'track_name': [],\n",
    "        'artists_name': [],\n",
    "        'track_duration': [],\n",
    "        'track_url': []\n",
    "         }\n",
    "    #providing same process for a titles\n",
    "        for i in range(len(track_name_tags)):\n",
    "            track_info = get_track_info(track_name_tags[i],artists_name_tags[i],track_duration_tags[i],track_url_tags[i])\n",
    "            topic_title_dict['track_name'].append(track_info[0])\n",
    "            topic_title_dict['artists_name'].append(track_info[1])\n",
    "            topic_title_dict['track_duration'].append(track_info[2])\n",
    "            topic_title_dict['track_url'].append(track_info[3])\n",
    "        return pd.DataFrame(topic_title_dict)\n",
    "    \n",
    "def scrape_topic(movie_name_url, topic_name):\n",
    "            topic_df = get_title_url(movie_name_url)\n",
    "            topic_df.to_csv(topic_name + '.csv', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "9d36a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_info():\n",
    "    print('scraping list of titles')\n",
    "    topic_df = scrape_titles_info()\n",
    "    \n",
    "    for index, row in topic_df.iterrows():\n",
    "        print('scrapping tracks for\"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "67ab9083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping list of titles\n",
      "scrapping tracks for\" K. G. F. 2 (Malayalam)\"\n",
      "scrapping tracks for\" Hridayam\"\n",
      "scrapping tracks for\" Bheeshma Parvam\"\n",
      "scrapping tracks for\" Hridayam (Side B)\"\n",
      "scrapping tracks for\" RRR (Malayalam)\"\n",
      "scrapping tracks for\" Minnal Murali\"\n",
      "scrapping tracks for\" Bro Daddy\"\n",
      "scrapping tracks for\" Ajagajantharam\"\n",
      "scrapping tracks for\" Dear Comrade - Malayalam\"\n",
      "scrapping tracks for\" Kurup - Malayalam\"\n",
      "scrapping tracks for\" Pushpa - The Rise (Malayalam)\"\n",
      "scrapping tracks for\" Happy Birthday Laaleten Special\"\n",
      "scrapping tracks for\" Bheeshma Parvam (Original Motion Picture Soundtrack)\"\n",
      "scrapping tracks for\" Sweet Melodies Nonstop Malayalam Superhits\"\n",
      "scrapping tracks for\" Member Rameshan 9aam Ward\"\n",
      "scrapping tracks for\" KGF Chapter 2 - Malayalam\"\n",
      "scrapping tracks for\" Sara'S (Original Motion Picture Soundtrack)\"\n",
      "scrapping tracks for\" Love Action Drama\"\n",
      "scrapping tracks for\" Melodies Of K J Yesudas\"\n",
      "scrapping tracks for\" Vettom\"\n",
      "scrapping tracks for\" Hridayam (Side A)\"\n",
      "scrapping tracks for\" Sallapam\"\n",
      "scrapping tracks for\" Kudukku 2025\"\n",
      "scrapping tracks for\" Sunny (Original Motion Picture Soundtrack)\"\n",
      "scrapping tracks for\" Niram\"\n",
      "scrapping tracks for\" Mollywood's Unforgettable Melodies\"\n",
      "scrapping tracks for\" Valentine's Day Special 2021 - Malayalam Romantic Songs\"\n",
      "scrapping tracks for\" Anugraheethan Antony\"\n",
      "scrapping tracks for\" Bhramam\"\n",
      "scrapping tracks for\" Adwaitham\"\n",
      "scrapping tracks for\" Edakkad Battalion 06\"\n",
      "scrapping tracks for\" Big Brother (Original Motion Picture Soundtrack)\"\n",
      "scrapping tracks for\" Pavithram (Original Motion Picture Soundtrack)\"\n",
      "scrapping tracks for\" Neeyen Kithab\"\n",
      "scrapping tracks for\" Mazhayethum Munpe\"\n",
      "scrapping tracks for\" Bahubali\"\n",
      "scrapping tracks for\" Gauthamante Radham\"\n",
      "scrapping tracks for\" Ayyappanum Koshiyum\"\n",
      "scrapping tracks for\" Sufiyum Sujatayum\"\n",
      "scrapping tracks for\" Thalavattom\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3b4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f0bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999c923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
